{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "from string import punctuation\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_data = pd.read_csv('./Data/agNews/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, 1])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Class Index'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Description'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Class Index'][8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train_data['Class Index']).tolist()\n",
    "description = np.array(train_data['Description']).tolist()\n",
    "title = np.array(train_data['Title']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [singleTitle + \" \" + description[i]  for i, singleTitle in enumerate(title)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([30000.,     0.,     0., 30000.,     0.,     0., 30000.,     0.,\n",
       "            0., 30000.]),\n",
       " array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAASkUlEQVR4nO3df6zddX3H8edLypAMQX5cWNOWlUizWEis0nRdSBZmzeh0WTGB5JIMmqVLHcFEM5MF/GPqH03kD2VhEZY6CIWp0KCOhtFtBDTGBIsXhpZSmTfC4NqGVkGo2WBrfe+P87nJ6e3pvefe2957D30+km/O97y/n8/3fj79RF/3+/2ee0hVIUnSu+Z7AJKkhcFAkCQBBoIkqTEQJEmAgSBJahbN9wBm6oILLqjly5fP9zAkaaA8/fTTv6iqoV7HBjYQli9fzsjIyHwPQ5IGSpL/Ot4xbxlJkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEnNlIGQ5N1JnkryoyR7knyh1c9L8liSn7bXc7v63JpkNMkLSa7uql+RZHc7dkeStPoZSR5s9V1Jlp+EuUqSJtHPFcLbwIer6gPAKmB9krXALcDjVbUCeLy9J8lKYBi4DFgP3JnktHauu4DNwIq2rW/1TcDrVXUpcDtw2+ynJkmajikDoTp+3d6e3rYCNgDbWn0bcE3b3wA8UFVvV9WLwCiwJsli4OyqerI6/xGG+yb0GT/XQ8C68asHSdLc6Osvldtv+E8DlwJfqapdSS6qqv0AVbU/yYWt+RLgB13dx1rt/9r+xPp4n1fauQ4neQM4H/jFhHFspnOFwcUXX9zvHI+x/JZ/mXHf2Xrpix+bt589X+br39t/67njv/XcOln/3n09VK6qI1W1ClhK57f9yydp3us3+5qkPlmfiePYWlWrq2r10FDPr+KQJM3QtD5lVFW/Ar5L597/q+02EO31QGs2Bizr6rYU2NfqS3vUj+qTZBFwDvDadMYmSZqdfj5lNJTkvW3/TOAjwE+AHcDG1mwj8HDb3wEMt08OXULn4fFT7fbSoSRr2/OBGyf0GT/XtcAT5X/sWZLmVD/PEBYD29pzhHcB26vqkSRPAtuTbAJeBq4DqKo9SbYDzwOHgZur6kg7103AvcCZwM62AdwN3J9klM6VwfCJmJwkqX9TBkJV/Rj4YI/6L4F1x+mzBdjSoz4CHPP8oareogWKJGl++JfKkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiSgj0BIsizJd5LsTbInyada/fNJfp7k2bZ9tKvPrUlGk7yQ5Oqu+hVJdrdjdyRJq5+R5MFW35Vk+UmYqyRpEv1cIRwGPlNV7wfWAjcnWdmO3V5Vq9r2KEA7NgxcBqwH7kxyWmt/F7AZWNG29a2+CXi9qi4Fbgdum/3UJEnTMWUgVNX+qnqm7R8C9gJLJumyAXigqt6uqheBUWBNksXA2VX1ZFUVcB9wTVefbW3/IWDd+NWDJGluTOsZQruV80FgVyt9MsmPk9yT5NxWWwK80tVtrNWWtP2J9aP6VNVh4A3g/B4/f3OSkSQjBw8enM7QJUlT6DsQkpwFfBP4dFW9Sef2z/uAVcB+4EvjTXt0r0nqk/U5ulC1tapWV9XqoaGhfocuSepDX4GQ5HQ6YfC1qvoWQFW9WlVHquo3wFeBNa35GLCsq/tSYF+rL+1RP6pPkkXAOcBrM5mQJGlm+vmUUYC7gb1V9eWu+uKuZh8Hnmv7O4Dh9smhS+g8PH6qqvYDh5Ksbee8EXi4q8/Gtn8t8ER7ziBJmiOL+mhzJXADsDvJs632WeD6JKvo3Np5CfgEQFXtSbIdeJ7OJ5Rurqojrd9NwL3AmcDOtkEncO5PMkrnymB4NpOSJE3flIFQVd+n9z3+RyfpswXY0qM+Alzeo/4WcN1UY5EknTz+pbIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEnNlIGQZFmS7yTZm2RPkk+1+nlJHkvy0/Z6blefW5OMJnkhydVd9SuS7G7H7kiSVj8jyYOtvivJ8pMwV0nSJPq5QjgMfKaq3g+sBW5OshK4BXi8qlYAj7f3tGPDwGXAeuDOJKe1c90FbAZWtG19q28CXq+qS4HbgdtOwNwkSdMwZSBU1f6qeqbtHwL2AkuADcC21mwbcE3b3wA8UFVvV9WLwCiwJsli4OyqerKqCrhvQp/xcz0ErBu/epAkzY1pPUNot3I+COwCLqqq/dAJDeDC1mwJ8EpXt7FWW9L2J9aP6lNVh4E3gPN7/PzNSUaSjBw8eHA6Q5ckTaHvQEhyFvBN4NNV9eZkTXvUapL6ZH2OLlRtrarVVbV6aGhoqiFLkqahr0BIcjqdMPhaVX2rlV9tt4ForwdafQxY1tV9KbCv1Zf2qB/VJ8ki4BzgtelORpI0c/18yijA3cDeqvpy16EdwMa2vxF4uKs+3D45dAmdh8dPtdtKh5Ksbee8cUKf8XNdCzzRnjNIkubIoj7aXAncAOxO8myrfRb4IrA9ySbgZeA6gKrak2Q78DydTyjdXFVHWr+bgHuBM4GdbYNO4NyfZJTOlcHw7KYlSZquKQOhqr5P73v8AOuO02cLsKVHfQS4vEf9LVqgSJLmh3+pLEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkC+giEJPckOZDkua7a55P8PMmzbfto17Fbk4wmeSHJ1V31K5LsbsfuSJJWPyPJg62+K8nyEzxHSVIf+rlCuBdY36N+e1WtatujAElWAsPAZa3PnUlOa+3vAjYDK9o2fs5NwOtVdSlwO3DbDOciSZqFKQOhqr4HvNbn+TYAD1TV21X1IjAKrEmyGDi7qp6sqgLuA67p6rOt7T8ErBu/epAkzZ3ZPEP4ZJIft1tK57baEuCVrjZjrbak7U+sH9Wnqg4DbwDn9/qBSTYnGUkycvDgwVkMXZI00UwD4S7gfcAqYD/wpVbv9Zt9TVKfrM+xxaqtVbW6qlYPDQ1Na8CSpMnNKBCq6tWqOlJVvwG+Cqxph8aAZV1NlwL7Wn1pj/pRfZIsAs6h/1tUkqQTZEaB0J4JjPs4MP4JpB3AcPvk0CV0Hh4/VVX7gUNJ1rbnAzcCD3f12dj2rwWeaM8ZJElzaNFUDZJ8A7gKuCDJGPA54Kokq+jc2nkJ+ARAVe1Jsh14HjgM3FxVR9qpbqLziaUzgZ1tA7gbuD/JKJ0rg+ETMC9J0jRNGQhVdX2P8t2TtN8CbOlRHwEu71F/C7huqnFIkk4u/1JZkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkZspASHJPkgNJnuuqnZfksSQ/ba/ndh27NclokheSXN1VvyLJ7nbsjiRp9TOSPNjqu5IsP8FzlCT1oZ8rhHuB9RNqtwCPV9UK4PH2niQrgWHgstbnziSntT53AZuBFW0bP+cm4PWquhS4HbhtppORJM3clIFQVd8DXptQ3gBsa/vbgGu66g9U1dtV9SIwCqxJshg4u6qerKoC7pvQZ/xcDwHrxq8eJElzZ6bPEC6qqv0A7fXCVl8CvNLVbqzVlrT9ifWj+lTVYeAN4PxePzTJ5iQjSUYOHjw4w6FLkno50Q+Ve/1mX5PUJ+tzbLFqa1WtrqrVQ0NDMxyiJKmXmQbCq+02EO31QKuPAcu62i0F9rX60h71o/okWQScw7G3qCRJJ9lMA2EHsLHtbwQe7qoPt08OXULn4fFT7bbSoSRr2/OBGyf0GT/XtcAT7TmDJGkOLZqqQZJvAFcBFyQZAz4HfBHYnmQT8DJwHUBV7UmyHXgeOAzcXFVH2qluovOJpTOBnW0DuBu4P8konSuD4RMyM0nStEwZCFV1/XEOrTtO+y3Alh71EeDyHvW3aIEiSZo//qWyJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAmYZSAkeSnJ7iTPJhlptfOSPJbkp+313K72tyYZTfJCkqu76le084wmuSNJZjMuSdL0nYgrhD+qqlVVtbq9vwV4vKpWAI+39yRZCQwDlwHrgTuTnNb63AVsBla0bf0JGJckaRpOxi2jDcC2tr8NuKar/kBVvV1VLwKjwJoki4Gzq+rJqirgvq4+kqQ5MttAKODfkzydZHOrXVRV+wHa64WtvgR4pavvWKstafsT68dIsjnJSJKRgwcPznLokqRui2bZ/8qq2pfkQuCxJD+ZpG2v5wI1Sf3YYtVWYCvA6tWre7aRJM3MrK4Qqmpfez0AfBtYA7zabgPRXg+05mPAsq7uS4F9rb60R12SNIdmHAhJfjvJe8b3gT8GngN2ABtbs43Aw21/BzCc5Iwkl9B5ePxUu610KMna9umiG7v6SJLmyGxuGV0EfLt9QnQR8PWq+tckPwS2J9kEvAxcB1BVe5JsB54HDgM3V9WRdq6bgHuBM4GdbZMkzaEZB0JV/Qz4QI/6L4F1x+mzBdjSoz4CXD7TsUiSZs+/VJYkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKlZMIGQZH2SF5KMJrllvscjSaeaBREISU4DvgL8CbASuD7JyvkdlSSdWhZEIABrgNGq+llV/S/wALBhnsckSaeUVNV8j4Ek1wLrq+ov2/sbgN+vqk9OaLcZ2Nze/h7wwgx/5AXAL2bYd6FxLgvPO2Ue4FwWqtnM5XeraqjXgUUzH88JlR61Y5KqqrYCW2f9w5KRqlo92/MsBM5l4XmnzAOcy0J1suayUG4ZjQHLut4vBfbN01gk6ZS0UALhh8CKJJck+S1gGNgxz2OSpFPKgrhlVFWHk3wS+DfgNOCeqtpzEn/krG87LSDOZeF5p8wDnMtCdVLmsiAeKkuS5t9CuWUkSZpnBoIkCXgHB0KSe5IcSPLccY4nyR3tqzJ+nORDcz3GfvUxl6uSvJHk2bb97VyPsR9JliX5TpK9SfYk+VSPNgOxLn3OZVDW5d1JnkryozaXL/RoMyjr0s9cBmJdoPMtDkn+I8kjPY6d+DWpqnfkBvwh8CHgueMc/yiwk87fQKwFds33mGcxl6uAR+Z7nH3MYzHwobb/HuA/gZWDuC59zmVQ1iXAWW3/dGAXsHZA16WfuQzEurSx/jXw9V7jPRlr8o69Qqiq7wGvTdJkA3BfdfwAeG+SxXMzuunpYy4Doar2V9Uzbf8QsBdYMqHZQKxLn3MZCO3f+tft7eltm/hpk0FZl37mMhCSLAU+BvzjcZqc8DV5xwZCH5YAr3S9H2NA/wfd/EG7TN6Z5LL5HsxUkiwHPkjnN7huA7cuk8wFBmRd2q2JZ4EDwGNVNbDr0sdcYDDW5e+AvwF+c5zjJ3xNTuVA6OvrMgbEM3S+n+QDwN8D/zy/w5lckrOAbwKfrqo3Jx7u0WXBrssUcxmYdamqI1W1is63BKxJcvmEJgOzLn3MZcGvS5I/BQ5U1dOTNetRm9WanMqB8I75uoyqenP8MrmqHgVOT3LBPA+rpySn0/k/0K9V1bd6NBmYdZlqLoO0LuOq6lfAd4H1Ew4NzLqMO95cBmRdrgT+LMlLdL79+cNJ/mlCmxO+JqdyIOwAbmxP6tcCb1TV/vke1Ewk+Z0kaftr6KzrL+d3VMdqY7wb2FtVXz5Os4FYl37mMkDrMpTkvW3/TOAjwE8mNBuUdZlyLoOwLlV1a1UtrarldL7K54mq+vMJzU74miyIr644GZJ8g86nCS5IMgZ8js4DJqrqH4BH6TylHwX+G/iL+Rnp1PqYy7XATUkOA/8DDFf7GMICcyVwA7C73eMF+CxwMQzcuvQzl0FZl8XAtnT+Q1XvArZX1SNJ/goGbl36mcugrMsxTvaa+NUVkiTg1L5lJEnqYiBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEnN/wOc5w1llMqzBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied Materials Reports Profit in 3Q Applied Materials Inc., the world #39;s largest supplier of machines that make computer chips, Tuesday said surging sales in its latest quarter surpassed its own and Wall Street estimates.  --> Business\n"
     ]
    }
   ],
   "source": [
    "print(data[2000] + \" --> \" + classes[labels[2000] - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreProcessing From here --> torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wall',\n",
       " 'st',\n",
       " '.',\n",
       " 'bears',\n",
       " 'claw',\n",
       " 'back',\n",
       " 'into',\n",
       " 'the',\n",
       " 'black',\n",
       " '(',\n",
       " 'reuters',\n",
       " ')',\n",
       " 'reuters',\n",
       " '-',\n",
       " 'short-sellers',\n",
       " ',',\n",
       " 'wall',\n",
       " 'street',\n",
       " \"'\",\n",
       " 's',\n",
       " 'dwindling\\\\band',\n",
       " 'of',\n",
       " 'ultra-cynics',\n",
       " ',',\n",
       " 'are',\n",
       " 'seeing',\n",
       " 'green',\n",
       " 'again',\n",
       " '.']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer, changing the values to tokens\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "tokenizer(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello cool'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = lambda x: ''.join([i for i in x if i not in punctuation])\n",
    "test = clean_data(\"Hello #cool\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(batch):\n",
    "    for i in batch:\n",
    "        yield tokenizer(i)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(data), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clean_data = [clean_data(i) for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wall St Bears Claw Back Into the Black Reuters Reuters  Shortsellers Wall Streets dwindlingband of ultracynics are seeing green again'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clean_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 23, 73]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"is new york\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1605]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('Bears')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ints = []\n",
    "\n",
    "for i in data:\n",
    "    data_ints.append(text_pipeline(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[431,\n",
       " 427,\n",
       " 1,\n",
       " 1605,\n",
       " 14836,\n",
       " 113,\n",
       " 66,\n",
       " 2,\n",
       " 848,\n",
       " 13,\n",
       " 27,\n",
       " 14,\n",
       " 27,\n",
       " 15,\n",
       " 50718,\n",
       " 3,\n",
       " 431,\n",
       " 374,\n",
       " 16,\n",
       " 9,\n",
       " 67497,\n",
       " 6,\n",
       " 52251,\n",
       " 3,\n",
       " 42,\n",
       " 4009,\n",
       " 782,\n",
       " 325,\n",
       " 1]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_idx = [i for i, review in enumerate(data_ints) if len(review) != 0]\n",
    "\n",
    "data_ints = [data_ints[i] for i in non_zero_idx]\n",
    "encoded_labels = np.array([label_pipeline(labels[i]) for i in non_zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "43.276516666666666\n"
     ]
    }
   ],
   "source": [
    "data_lens = [len(i) for i in data_ints]\n",
    "print(len(data))\n",
    "print(np.mean(data_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(data_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(data_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(data_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features\n",
    "\n",
    "seq_length = 45\n",
    "features = pad_features(data_ints,seq_length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(np.array(features), encoded_labels, train_size=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_data, dtype=torch.float), torch.tensor(train_labels, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(test_data, dtype=torch.float), torch.tensor(test_labels, dtype=torch.long))\n",
    "\n",
    "batch_size = 30\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 45])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newsRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim ,hidden_dim, output_dim, n_layers) -> None:\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_dim\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,hidden_dim, n_layers)\n",
    "        self.fcl = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x.long()\n",
    "\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "\n",
    "        out = self.fcl(lstm_out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                    weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "output = 4\n",
    "n_layers = 2\n",
    "hidden_dim = 400\n",
    "\n",
    "net = newsRNN(vocab_size, embedding_dim, hidden_dim, output, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "\n",
    "yhat = net(X, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.3333)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 *torch.mean((yhat.argmax(1) == y).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNNModel():\n",
    "    numepochs = 10\n",
    "    losses = torch.zeros(numepochs)\n",
    "    totalAccuracy = []\n",
    "    net = newsRNN(vocab_size, embedding_dim, hidden_dim, output, n_layers)\n",
    "    net = net.to(device)\n",
    "\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(numepochs):\n",
    "        batchAccuracy = []\n",
    "        batchLosses = []\n",
    "\n",
    "        h = net.init_hidden(batch_size)\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            h = tuple([each.data for each in h])\n",
    "            yhat, h = net(X, h)\n",
    "\n",
    "            loss = lossfun(yhat.squeeze(), y)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batchLosses.append(loss.item())\n",
    "\n",
    "            accuracy = 100 * torch.mean((yhat.argmax(1) == y).float())\n",
    "            batchAccuracy.append(accuracy.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        losses[epoch] = np.mean(batchLosses)\n",
    "        totalAccuracy.append(np.mean(batchAccuracy))\n",
    "\n",
    "    return losses, totalAccuracy, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RnnLosses, RnnAcc, RnnNet = trainRNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model --> No Rnn computations from this point onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearModel(vocab_size, embedding_dim):\n",
    "    class model(nn.Module):\n",
    "        def __init__(self, vocab_size, embedding_dim) -> None:\n",
    "            super().__init__()\n",
    "            self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
    "            self.fc1 = nn.Linear(embedding_dim, 16)\n",
    "            self.fc2 = nn.Linear(16, 16)\n",
    "            self.output = nn.Linear(16, 4)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = x.long()\n",
    "            embedded = self.embedding(x)\n",
    "            x = torch.relu(self.fc1(embedded))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.output(x)\n",
    "            return x\n",
    "    net = model(vocab_size, embedding_dim)\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=.1)\n",
    "\n",
    "    return net, lossfun, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearNet, lossfun, optimizer = LinearModel(vocab_size, embedding_dim ) \n",
    "X, y = next(iter(train_loader))\n",
    "yhat = LinearNet(X)\n",
    "yhat.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3625, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossfun(yhat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.66666793823242"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyT = 100 * torch.mean((yhat.argmax(1) == y).float())\n",
    "accuracyT.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    numepochs = 10\n",
    "    losses = torch.zeros(numepochs)\n",
    "    totalAccuracy = []\n",
    "    net, lossfun, optimizer = LinearModel(vocab_size, embedding_dim ) \n",
    "    net = net.to(device)\n",
    "\n",
    "    for epoch in range(numepochs):\n",
    "        batchAccuracy = []\n",
    "        batchLosses = []\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            yhat = net(X)\n",
    "\n",
    "            loss = lossfun(yhat, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "            batchLosses.append(loss.item())\n",
    "\n",
    "            accuracy = 100 * torch.mean((yhat.argmax(1) == y).float())\n",
    "            batchAccuracy.append(accuracy.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        losses[epoch] = np.mean(batchLosses)\n",
    "        totalAccuracy.append(np.mean(batchAccuracy))\n",
    "\n",
    "    return losses, totalAccuracy, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5244/1273881962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5244/2088769706.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LinearLosses, LinearAccuracy, LinearNet = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff959db8370>]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24100, 3722, 2347]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"hi im cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "offsets has to be a 1D Tensor but got None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5244/2321512040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kaya\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5244/2321512040.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(text, text_pipeline)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5244/1633080655.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0mreturned\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         return F.embedding_bag(input, self.weight, offsets,\n\u001b[0m\u001b[1;32m    384\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding_bag\u001b[0;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[1;32m   2188\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"offsets has to be a 1D Tensor but got None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"offsets has to be a 1D Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: offsets has to be a 1D Tensor but got None"
     ]
    }
   ],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = LinearNet(text)\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "predict(\"Kaya\", text_pipeline)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2156b30ccf86f12cce57017c1d0afff085ab473cf0ed28ab0cdf74a42358ab99"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
